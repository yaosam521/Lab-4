{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6601edd3-0940-411b-a792-da8e9cec2da4",
   "metadata": {},
   "source": [
    "# Lab 4 - Multilayer Perceptron\n",
    "Team members:\n",
    "- Sam Yao\n",
    "- Rebecca Kuhlman\n",
    "- Michael Amberg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3c892f-d3b5-46dd-89d2-fe55e27c9ff9",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The objective of this lab is to familiarize ourselves with MultiLayer Neural Networks. This will be done through predicting, for each county, the level of child poverty. You will need to convert this from regression to four levels of classification by quantizing the variable of interest.\n",
    "\n",
    "1) Load the data into memory and save it to a pandas data frame. Do not normalize or one-hot encode any of the features until asked to do so later in the rubric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca9ccc4-db84-4201-8e86-449c713337b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_census_raw = pd.read_csv(\"acs2017_census_tract_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfea931e-39e7-47c6-98e2-dd321fbee5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74001 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           74001 non-null  int64  \n",
      " 1   State             74001 non-null  object \n",
      " 2   County            74001 non-null  object \n",
      " 3   TotalPop          74001 non-null  int64  \n",
      " 4   Men               74001 non-null  int64  \n",
      " 5   Women             74001 non-null  int64  \n",
      " 6   Hispanic          73305 non-null  float64\n",
      " 7   White             73305 non-null  float64\n",
      " 8   Black             73305 non-null  float64\n",
      " 9   Native            73305 non-null  float64\n",
      " 10  Asian             73305 non-null  float64\n",
      " 11  Pacific           73305 non-null  float64\n",
      " 12  VotingAgeCitizen  74001 non-null  int64  \n",
      " 13  Income            72885 non-null  float64\n",
      " 14  IncomeErr         72885 non-null  float64\n",
      " 15  IncomePerCap      73256 non-null  float64\n",
      " 16  IncomePerCapErr   73256 non-null  float64\n",
      " 17  Poverty           73159 non-null  float64\n",
      " 18  ChildPoverty      72891 non-null  float64\n",
      " 19  Professional      73190 non-null  float64\n",
      " 20  Service           73190 non-null  float64\n",
      " 21  Office            73190 non-null  float64\n",
      " 22  Construction      73190 non-null  float64\n",
      " 23  Production        73190 non-null  float64\n",
      " 24  Drive             73200 non-null  float64\n",
      " 25  Carpool           73200 non-null  float64\n",
      " 26  Transit           73200 non-null  float64\n",
      " 27  Walk              73200 non-null  float64\n",
      " 28  OtherTransp       73200 non-null  float64\n",
      " 29  WorkAtHome        73200 non-null  float64\n",
      " 30  MeanCommute       73055 non-null  float64\n",
      " 31  Employed          74001 non-null  int64  \n",
      " 32  PrivateWork       73190 non-null  float64\n",
      " 33  PublicWork        73190 non-null  float64\n",
      " 34  SelfEmployed      73190 non-null  float64\n",
      " 35  FamilyWork        73190 non-null  float64\n",
      " 36  Unemployment      73191 non-null  float64\n",
      "dtypes: float64(29), int64(6), object(2)\n",
      "memory usage: 20.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_census_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbedbea-e014-4c1e-bde6-3e0edbaf3d32",
   "metadata": {},
   "source": [
    "2) Remove any observations that having missing data. \n",
    "\n",
    "Source used for this section:\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12116e9f-a14c-4d29-a71d-1ce6635d4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census_raw = df_census_raw.dropna() #Utilized the pandas documentation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eebd3207-c2f2-49b1-9fb2-78520ec62fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72718 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           72718 non-null  int64  \n",
      " 1   State             72718 non-null  object \n",
      " 2   County            72718 non-null  object \n",
      " 3   TotalPop          72718 non-null  int64  \n",
      " 4   Men               72718 non-null  int64  \n",
      " 5   Women             72718 non-null  int64  \n",
      " 6   Hispanic          72718 non-null  float64\n",
      " 7   White             72718 non-null  float64\n",
      " 8   Black             72718 non-null  float64\n",
      " 9   Native            72718 non-null  float64\n",
      " 10  Asian             72718 non-null  float64\n",
      " 11  Pacific           72718 non-null  float64\n",
      " 12  VotingAgeCitizen  72718 non-null  int64  \n",
      " 13  Income            72718 non-null  float64\n",
      " 14  IncomeErr         72718 non-null  float64\n",
      " 15  IncomePerCap      72718 non-null  float64\n",
      " 16  IncomePerCapErr   72718 non-null  float64\n",
      " 17  Poverty           72718 non-null  float64\n",
      " 18  ChildPoverty      72718 non-null  float64\n",
      " 19  Professional      72718 non-null  float64\n",
      " 20  Service           72718 non-null  float64\n",
      " 21  Office            72718 non-null  float64\n",
      " 22  Construction      72718 non-null  float64\n",
      " 23  Production        72718 non-null  float64\n",
      " 24  Drive             72718 non-null  float64\n",
      " 25  Carpool           72718 non-null  float64\n",
      " 26  Transit           72718 non-null  float64\n",
      " 27  Walk              72718 non-null  float64\n",
      " 28  OtherTransp       72718 non-null  float64\n",
      " 29  WorkAtHome        72718 non-null  float64\n",
      " 30  MeanCommute       72718 non-null  float64\n",
      " 31  Employed          72718 non-null  int64  \n",
      " 32  PrivateWork       72718 non-null  float64\n",
      " 33  PublicWork        72718 non-null  float64\n",
      " 34  SelfEmployed      72718 non-null  float64\n",
      " 35  FamilyWork        72718 non-null  float64\n",
      " 36  Unemployment      72718 non-null  float64\n",
      "dtypes: float64(29), int64(6), object(2)\n",
      "memory usage: 21.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_census_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06acf1ae-ec73-4b27-91de-77e994902e3f",
   "metadata": {},
   "source": [
    "3) Encode any string data as integers for now.\n",
    "\n",
    "There are two categories that are not numerical: State and County.\n",
    "\n",
    "I encoded the states and individual counties as nominal types, where each number corresponds to a unique county and state, and has no ranking whatsoever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7948c42-4454-4171-aba3-884a76a672ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map States to a number\n",
    "states_mapping = {state: label for label, state in enumerate(df_census_raw.State.unique())}\n",
    "df_census_raw['State'] = df_census_raw['State'].map(states_mapping)\n",
    "\n",
    "#Map Counties to a number\n",
    "county_mapping = {county: label for label, county in enumerate(df_census_raw.County.unique())}\n",
    "df_census_raw['County'] = df_census_raw['County'].map(county_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd141f-c18d-4192-9924-41b01b046db1",
   "metadata": {},
   "source": [
    "We have decided to remove the county variable. While county can be a indicator of childhood poverty, due to the limited amount of entries for each county, the data will likely be biased on what data ends up in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062a217d-b0b7-4922-9e3c-ee09f37637d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186     2300\n",
       "366     1317\n",
       "196      929\n",
       "103      885\n",
       "50       822\n",
       "        ... \n",
       "1755       1\n",
       "1066       1\n",
       "663        1\n",
       "1065       1\n",
       "1651       1\n",
       "Name: County, Length: 1954, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census_raw.County.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570c83e6-fc4d-49c1-bcbb-ec26aa49bf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_census_raw.County.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b74c4-a6c7-4b47-b1dc-cad50e51952d",
   "metadata": {},
   "source": [
    "Even without this handy visualization, one can see that there are too many counties with too few data points to  begin analysis on child poverty. Although there certainly are patterns as to which counties in a state are more likely to have children in poverty, leaving the county attribute as it is would most likely introduce bias towards the counties that have the highest rates of child poverty. Since child poverty is certainly influenced by several other factors other than physical county location, we think it is best to remove Counties as an attribute from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391ef7b0-8a6d-452c-b2c8-3d5e624ebe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census_raw = df_census_raw.drop(labels='County',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a4d5043-9cbc-4b1a-9d2d-27ff9873ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72718 entries, 0 to 74000\n",
      "Data columns (total 36 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TractId           72718 non-null  int64  \n",
      " 1   State             72718 non-null  int64  \n",
      " 2   TotalPop          72718 non-null  int64  \n",
      " 3   Men               72718 non-null  int64  \n",
      " 4   Women             72718 non-null  int64  \n",
      " 5   Hispanic          72718 non-null  float64\n",
      " 6   White             72718 non-null  float64\n",
      " 7   Black             72718 non-null  float64\n",
      " 8   Native            72718 non-null  float64\n",
      " 9   Asian             72718 non-null  float64\n",
      " 10  Pacific           72718 non-null  float64\n",
      " 11  VotingAgeCitizen  72718 non-null  int64  \n",
      " 12  Income            72718 non-null  float64\n",
      " 13  IncomeErr         72718 non-null  float64\n",
      " 14  IncomePerCap      72718 non-null  float64\n",
      " 15  IncomePerCapErr   72718 non-null  float64\n",
      " 16  Poverty           72718 non-null  float64\n",
      " 17  ChildPoverty      72718 non-null  float64\n",
      " 18  Professional      72718 non-null  float64\n",
      " 19  Service           72718 non-null  float64\n",
      " 20  Office            72718 non-null  float64\n",
      " 21  Construction      72718 non-null  float64\n",
      " 22  Production        72718 non-null  float64\n",
      " 23  Drive             72718 non-null  float64\n",
      " 24  Carpool           72718 non-null  float64\n",
      " 25  Transit           72718 non-null  float64\n",
      " 26  Walk              72718 non-null  float64\n",
      " 27  OtherTransp       72718 non-null  float64\n",
      " 28  WorkAtHome        72718 non-null  float64\n",
      " 29  MeanCommute       72718 non-null  float64\n",
      " 30  Employed          72718 non-null  int64  \n",
      " 31  PrivateWork       72718 non-null  float64\n",
      " 32  PublicWork        72718 non-null  float64\n",
      " 33  SelfEmployed      72718 non-null  float64\n",
      " 34  FamilyWork        72718 non-null  float64\n",
      " 35  Unemployment      72718 non-null  float64\n",
      "dtypes: float64(29), int64(7)\n",
      "memory usage: 20.5 MB\n"
     ]
    }
   ],
   "source": [
    "df_census_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488a910f-ce61-49a6-a5fc-1debc16fdfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    72718.000000\n",
       "mean        21.148476\n",
       "std         18.572714\n",
       "min          0.000000\n",
       "25%          6.200000\n",
       "50%         16.300000\n",
       "75%         31.600000\n",
       "max        100.000000\n",
       "Name: ChildPoverty, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_census_raw['ChildPoverty'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33d19154-9f07-46d0-8ec3-5250fd2d0b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([25612., 15946., 11393.,  7936.,  5289.,  3352.,  1810.,   887.,\n",
       "          345.,   148.]),\n",
       " array([  0.,  10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df_census_raw.ChildPoverty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0528b57",
   "metadata": {},
   "source": [
    ".5 points] Balance the dataset so that about the same number of instances are within each class. Choose a method for balancing the dataset and explain your reasoning for selecting this method. One option is to choose quantization thresholds for the \"ChildPoverty\" variable that equally divide the data into four classes. Should balancing of the dataset be done for both the training and testing set? Explain.\n",
    "\n",
    "\n",
    "Utilized Code Sourced here:\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.qcut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d66090-d3bd-40d8-b468-0d51691623c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TractId               int64\n",
       "State                 int64\n",
       "TotalPop              int64\n",
       "Men                   int64\n",
       "Women                 int64\n",
       "Hispanic            float64\n",
       "White               float64\n",
       "Black               float64\n",
       "Native              float64\n",
       "Asian               float64\n",
       "Pacific             float64\n",
       "VotingAgeCitizen      int64\n",
       "Income              float64\n",
       "IncomeErr           float64\n",
       "IncomePerCap        float64\n",
       "IncomePerCapErr     float64\n",
       "Poverty             float64\n",
       "ChildPoverty          int64\n",
       "Professional        float64\n",
       "Service             float64\n",
       "Office              float64\n",
       "Construction        float64\n",
       "Production          float64\n",
       "Drive               float64\n",
       "Carpool             float64\n",
       "Transit             float64\n",
       "Walk                float64\n",
       "OtherTransp         float64\n",
       "WorkAtHome          float64\n",
       "MeanCommute         float64\n",
       "Employed              int64\n",
       "PrivateWork         float64\n",
       "PublicWork          float64\n",
       "SelfEmployed        float64\n",
       "FamilyWork          float64\n",
       "Unemployment        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looked at Documentation for pandas.qcut()\n",
    "\n",
    "df_census_raw.ChildPoverty, bins= pd.qcut(df_census_raw.ChildPoverty, 4,labels=[1,2,3,4], retbins=True)\n",
    "df_census_raw.astype({'ChildPoverty': 'int64'}).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db7085-b1ba-4ce8-b93c-19903cbdfcd9",
   "metadata": {},
   "source": [
    "For quantization, we went with splitting the target output into four different bins using equal frequency. For training and testing, it would be important to balance the datasets. This is because if you don't balance the dataset, this could end in a situation where there are too many of one variable in the test dataset, but not the training dataset, and this would cause the model to perform poorly.\n",
    "\n",
    "In this particular case, we are shuffling the train_test_split method to balance this out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f9483-705d-48ef-b72b-9be36eacaa62",
   "metadata": {},
   "source": [
    "[.5 points] Assume you are equally interested in the classification performance for each class in the dataset. Split the dataset into 80% for training and 20% for testing. There is NO NEED to split the data multiple times for this lab.\n",
    "\n",
    "Note: You will need to one hot encode the target, but do not one hot encode the categorical data until instructed to do so in the lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329e597-956a-4b9c-b95a-6608060791eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X =\n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985eded",
   "metadata": {},
   "source": [
    "            [.5 points] Balance the dataset so that about the same number of instances are within each class. Choose a method for balancing the dataset and explain your reasoning for selecting this method. One option is to choose quantization thresholds for the \"ChildPoverty\" variable that equally divide the data into four classes. Should balancing of the dataset be done for both the training and testing set? Explain.\n",
    "            [.5 points] Assume you are equally interested in the classification performance for each class in the dataset. Split the dataset into 80% for training and 20% for testing. There is NO NEED to split the data multiple times for this lab.\n",
    "        Note: You will need to one hot encode the target, but do not one hot encode the categorical data until instructed to do so in the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5714a",
   "metadata": {},
   "source": [
    "The balancing of the data is not necessary for the testing set. In reality, a deployed algorithm will not encounter balanced data. The balanced data is important in the training set as it makes sure the model will be able to predict data across the board in a non-biased way. Testing data does not influence the algorithm directly, though it is important to test a variety of circumstances before deployment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4906e7",
   "metadata": {},
   "source": [
    "Pre-processing and Initial Modeling (2.5 points total)\n",
    "        You will be using a two layer perceptron from class for the next few parts of the rubric. There are several versions of the two layer perceptron covered in class, with example code. When selecting an example two layer network from class be sure that you use: (1) vectorized gradient computation, (2) mini-batching, (3) cross entropy loss, and (4) proper Glorot initialization, at a minimum. There is no need to use momentum or learning rate reduction (assuming you choose a sufficiently small learning rate). It is recommended to use sigmoids throughout the network, but not required.\n",
    "        [.5 points] Use the example two-layer perceptron network from the class example and quantify performance using accuracy. Do not normalize or one-hot encode the data (not yet). Be sure that training converges by graphing the loss function versus the number of epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a14e95a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "#Original Author: Sebastian Raschka\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "# Start with the following functions:\n",
    "#    init\n",
    "#    encode_labels\n",
    "#    initialize weights\n",
    "#    sigmoid\n",
    "#    add bias (vector of ones)\n",
    "#    objective function (cost and regularizer)\n",
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "\n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "\n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1_num_elems = (self.n_features_ + 1)*self.n_hidden\n",
    "        W1 = np.random.uniform(-1.0, 1.0, size=W1_num_elems)\n",
    "        W1 = W1.reshape(self.n_hidden, self.n_features_ + 1) # reshape to be W\n",
    "\n",
    "        W2_num_elems = (self.n_hidden + 1)*self.n_output_\n",
    "        W2 = np.random.uniform(-1.0, 1.0, size=W2_num_elems)\n",
    "        W2 = W2.reshape(self.n_output_, self.n_hidden + 1)\n",
    "        return W1, W2\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "\n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "\n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_) * np.sqrt(np.mean(W1[:, 1:] ** 2) + np.mean(W2[:, 1:] ** 2))\n",
    "\n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7bf1e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# now let's add in the following functions:\n",
    "#    feedforward\n",
    "#    fit and predict\n",
    "class TwoLayerPerceptron(TwoLayerPerceptronBase):\n",
    "    def _feedforward(self, X, W1, W2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        -----------\n",
    "        X : Input layer with original features.\n",
    "        W1: Weight matrix for input layer -> hidden layer.\n",
    "        W2: Weight matrix for hidden layer -> output layer.\n",
    "        ----------\n",
    "        a1-a3 : activations into layer (or output layer)\n",
    "        z1-z2 : layer inputs\n",
    "\n",
    "        \"\"\"\n",
    "        A1 = self._add_bias_unit(X.T, how='row')\n",
    "        Z1 = W1 @ A1\n",
    "        A2 = self._sigmoid(Z1)\n",
    "        A2 = self._add_bias_unit(A2, how='row')\n",
    "        Z2 = W2 @ A2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "\n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # need to vectorize this computation!\n",
    "        # See additional code and derivation below!\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data.\"\"\"\n",
    "\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "\n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        self.cost_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            # feedforward all instances\n",
    "            A1, Z1, A2, Z2, A3 = self._feedforward(X_data,self.W1,self.W2)\n",
    "\n",
    "            cost = self._cost(A3,Y_enc,self.W1,self.W2)\n",
    "            self.cost_.append(cost)\n",
    "\n",
    "            # compute gradient via backpropagation\n",
    "            grad1, grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, Y_enc=Y_enc,\n",
    "                                              W1=self.W1, W2=self.W2)\n",
    "\n",
    "            self.W1 -= self.eta * grad1\n",
    "            self.W2 -= self.eta * grad2\n",
    "\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf348922",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "params = dict(n_hidden=50,\n",
    "              C=0.1, # tradeoff L2 regularizer\n",
    "              epochs=400, # iterations\n",
    "              eta=0.001,  # learning rate\n",
    "              random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b1bed",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class TwoLayerPerceptronVectorized(TwoLayerPerceptron):\n",
    "    # just need a different gradient calculation\n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        V2 = -2*(Y_enc-A3)*A3*(1-A3)\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "\n",
    "        grad2 = V2 @ A2.T\n",
    "        grad1 = V1[1:,:] @ A1.T\n",
    "\n",
    "\n",
    "        # regularize weights that are not bias terms\n",
    "        grad1[:, 1:] += W1[:, 1:] * self.l2_C\n",
    "        grad2[:, 1:] += W2[:, 1:] * self.l2_C\n",
    "\n",
    "        return grad1, grad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8085b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "nn = TwoLayerPerceptronVectorized(**params)\n",
    "\n",
    "nn.fit(X_train, y_train, print_progress=50)\n",
    "yhat = nn.predict(X_test)\n",
    "print('Accuracy:',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef97bb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# take the mean of each minibatch epoch\n",
    "cost_avgs = [np.mean(x) for x in nn_mini.cost_]\n",
    "\n",
    "plt.plot(range(len(cost_avgs)), cost_avgs, color='red')\n",
    "plt.ylabel('Cost')\n",
    "plt.xlabel('Epochs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0bc4c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdc191",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_bfgs\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "class TLPVectorizedBFGS(TwoLayerPerceptronVectorized):\n",
    "\n",
    "    def __init__(self, gtol=1e-5, **kwds):\n",
    "        # need to add to the original initializer\n",
    "        self.gtol = gtol\n",
    "\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds)\n",
    "\n",
    "    @staticmethod\n",
    "    def _pack(in1, in2):\n",
    "        '''Pack and flatten input vectors '''\n",
    "        return np.hstack((in1.flatten(),in2.flatten()))\n",
    "\n",
    "    def _unpack(self, in_tot):\n",
    "        '''Undo packing according to layer weight sizes'''\n",
    "        out1 = in_tot[:self.W1.size].reshape(self.W1.shape)\n",
    "        out2 = in_tot[self.W1.size:].reshape(self.W2.shape)\n",
    "        return out1, out2\n",
    "\n",
    "    def _calc_cost_gradient_packed(self,W,X_data,Y_enc):\n",
    "        '''Unpack and get cost, gradient for bfgs'''\n",
    "        W1, W2 = self._unpack(W)\n",
    "        # feedforward all instances\n",
    "        A1, Z1, A2, Z2, A3 = self._feedforward(X_data,W1,W2)\n",
    "\n",
    "        cost = np.sum((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        cost = cost + L2_term\n",
    "        #perform back prop to get gradients\n",
    "        grad1,grad2 = self._get_gradient(A1=A1, A2=A2, A3=A3,Z1=Z1, Z2=Z2, Y_enc=Y_enc,\n",
    "                                         W1=W1, W2=W2)\n",
    "        return cost, self._pack(grad1,grad2)\n",
    "\n",
    "    def _cost_packed(self,W,X_data,Y_enc):\n",
    "        '''Unpack and calculate MSE for bfgs'''\n",
    "        W1, W2 = self._unpack(W)\n",
    "        _, _, _, _, A3 = self._feedforward(X_data,W1,W2)\n",
    "        return np.sum((Y_enc-A3)**2)\n",
    "\n",
    "    def fit(self,X,y,print_progress=0):\n",
    "        '''Learn weights from training data'''\n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "\n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2 = self._initialize_weights()\n",
    "\n",
    "        # make initial matrices into single row vector\n",
    "        W = self._pack(self.W1,self.W2)\n",
    "\n",
    "        if print_progress>0:\n",
    "            def callback(xd):\n",
    "                callback.counter += 1\n",
    "                if callback.counter%print_progress==0:\n",
    "                    sys.stderr.write('\\rEpoch: %d/%d (max)' % (callback.counter,callback.epochs))\n",
    "                    sys.stderr.flush()\n",
    "\n",
    "            callback.counter = 0\n",
    "            callback.epochs = self.epochs\n",
    "\n",
    "        else:\n",
    "            callback = None\n",
    "\n",
    "        # compute gradient optimum with bfgs\n",
    "        W_best,_,props = fmin_l_bfgs_b(\n",
    "                        x0=W,\n",
    "                        func=self._calc_cost_gradient_packed,\n",
    "                        maxfun=self.epochs,\n",
    "                        callback=callback,\n",
    "                        pgtol=self.gtol,\n",
    "                        args=(X_data, Y_enc))\n",
    "\n",
    "        self.W1, self.W2 = self._unpack(W_best)\n",
    "        if print_progress:\n",
    "            print(props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c742c0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nn_bfgs = TLPVectorizedBFGS(**params, gtol=1e-3)\n",
    "\n",
    "nn_bfgs.fit(X_train, y_train, print_progress=1)\n",
    "yhat = nn_bfgs.predict(X_test)\n",
    "print('Accuracy:',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d89ab",
   "metadata": {},
   "source": [
    "[.5 points] Now (1) normalize the continuous numeric feature data. Use the example two-layer perceptron network from the class example and quantify performance using accuracy. Be sure that training converges by graphing the loss function versus the number of epochs.\n",
    "        [.5 points] Now(1) normalize the continuous numeric feature data AND (2) one hot encode the categorical data. Use the example two-layer perceptron network from the class example and quantify performance using accuracy. Be sure that training converges by graphing the loss function versus the number of epochs.\n",
    "        [1 points] Compare the performance of the three models you just trained. Are there any meaningful differences in performance? Explain, in your own words, why these models have (or do not have) different performances.\n",
    "            Use one-hot encoding and normalization on the dataset for the remainder of this lab assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a75c370",
   "metadata": {},
   "source": [
    "Modeling (5 points total)\n",
    "        [1 points] Add support for a third layer in the multi-layer perceptron. Add support for saving (and plotting after training is completed) the average magnitude of the gradient for each layer, for each epoch (like we did in the flipped module for back propagation). For magnitude calculation, you are free to use either the average absolute values or the L1/L2 norm.\n",
    "            Quantify the performance of the model and graph the magnitudes for each layer versus the number of epochs.\n",
    "        [1 points] Repeat the previous step, adding support for a fourth layer.\n",
    "        [1 points] Repeat the previous step, adding support for a fifth layer.\n",
    "        [2 points] Implement an adaptive learning technique that was discussed in lecture and use it on the five layer network (such as AdaGrad, RMSProps, or AdaDelta).\n",
    "         Discuss which adaptive method you chose.\n",
    "         Compare the performance of your five layer model with and without the adaptive learning strategy. Do not use AdaM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec0c4b",
   "metadata": {},
   "source": [
    "Exceptional Work (1 points total)\n",
    "       Implement adaptive momentum (AdaM) in the five layer neural network and quantify the performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
